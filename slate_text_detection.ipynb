{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563aa09fdb754dfe9ea97b6cbb5acf10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c6c84f699d4fe1920ce29769fcb206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3535a376494abab6879976fd208ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6ce6a834e6435c8989694a649f140e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca098ca457f4cb0b4aa3a96a56565ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d512cbba85f64fde8b2f7628ffbff763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7597350e3d4754b968ff15947c3907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48395d608f524cc08ba17a91f2925ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-large-printed\")\n",
    "ocr_model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-large-printed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_FILEPATH = 'testdata/20210111_DML2387.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(VIDEO_FILEPATH)\n",
    "if not video.isOpened():\n",
    "    raise RuntimeError('Video opening failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMOUNT\n",
      "TOTAL AMOUNT\n",
      "TOTAL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL WITH ALL ALL ALL ALL ALL ALL\n",
      "TOTAL AMOUNT\n",
      "TOTAL AMOUNT\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL AMOUNT\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "BARRY\n",
      "TOTAL AMOUNT\n",
      "AMOUNT\n",
      "TOTAL AMOUNT\n",
      "TOTAL :\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL :\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n",
      "TOTAL\n"
     ]
    }
   ],
   "source": [
    "interesting_images = []\n",
    "count = 0\n",
    "step_size = 10\n",
    "while video.isOpened():\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, count)\n",
    "    count += step_size\n",
    "    ret, frame = video.read()\n",
    "    if not ret: break\n",
    "\n",
    "    h, w, c = frame.shape\n",
    "    frame = cv2.resize(frame, (w//4, h//4))\n",
    "    frame = Image.fromarray(frame)\n",
    "    pixel_values = processor(frame, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = ocr_model.generate(pixel_values)\n",
    "\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    print(generated_text)\n",
    "    if count > 500: break\n",
    "\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sorted(interesting_images, key=lambda t: t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in reversed(s):\n",
    "    plt.imshow(t[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
